---
{"dg-publish":true,"permalink":"/050 Base de Conocimientos/200  Mi Zettelkasten/100 Docencia/Org1/2025/Clase 06 Sistemas (Fronteras, Complejidad y Tipologías)/Zk Entropía/","tags":["digitalGarden","entropía"]}
---

## Entropía

La entropía es un concepto fundamental en la física y la teoría de sistemas, que se refiere al grado de desorden o aleatoriedad en un sistema. En el contexto de la termodinámica, la entropía mide la cantidad de energía no disponible para realizar trabajo en un sistema. Sin embargo, en sistemas complejos, la entropía también puede ser vista como un indicador de la complejidad y la variedad del sistema, como se discute en [[050 Base de Conocimientos/900 Biblioteca/Zk Lit (Johansen Bertoglio, 2013) Introducción a la Teoría General de Sistemas\|Johansen Bertoglio (2013)]].

### Definición

La entropía se define como una medida del desorden o la incertidumbre en un sistema. En sistemas físicos, esto se relaciona con la cantidad de energía que no está disponible para realizar trabajo útil. En sistemas complejos, como los sociales o económicos, la entropía puede ser interpretada como una medida de la diversidad y la complejidad de las interacciones entre sus componentes ([[050 Base de Conocimientos/200  Mi Zettelkasten/040 Teoría General de Sistemas (TGS)/Zk (García, 2024) Ciencias de la Complejidad - Teoría General de Sistemas, Pensamiento Sistémico y sus aplicaciones prácticas en las ciencias económicas, ambientales y sociales\|García, 2024]]; [[050 Base de Conocimientos/900 Biblioteca/Zk Lit (von Bertalanffy, 1989) Teoría General de los Sistemas Fundamentos, Desarrollo, Aplicaciones\|von Bertalanffy, 1989]]).

### Tipos de Entropía

- **Entropía Termodinámica**: Se refiere al desorden molecular en un sistema físico. A medida que la entropía aumenta, la energía disponible para realizar trabajo disminuye ([[050 Base de Conocimientos/200  Mi Zettelkasten/040 Teoría General de Sistemas (TGS)/Zk (Ossa Ossa, 2016) Teoría General de Sistemas -  Conceptos y Aplicaciones\|Ossa Ossa, 2016]]).

- **Entropía de la Información**: Desarrollada por Claude Shannon, mide la incertidumbre o la cantidad de información en un mensaje. En sistemas complejos, esta entropía puede ser usada para evaluar la complejidad de las interacciones y la diversidad de los componentes [[050 Base de Conocimientos/900 Biblioteca/Zk Lit (Johansen Bertoglio, 2013) Introducción a la Teoría General de Sistemas\|(Johansen, 2013)]].

### Importancia en Sistemas Complejos

Entender el concepto de la entropía es crucial en sistemas complejos, porque refleja su capacidad para adaptarse y evolucionar. Un sistema con alta entropía puede ser más adaptable a cambios en su entorno, pero también puede ser más propenso a la inestabilidad. La entropía se utiliza en diversas disciplinas, como la sostenibilidad urbana, donde ayuda a evaluar la eficiencia y la complejidad de los sistemas urbanos. Según [[050 Base de Conocimientos/900 Biblioteca/Zk Lit (García, 2020) Teoría y Ejercicios Prácticos de Dinámica de Sistemas\|García (2020)]], la entropía es un indicador valioso para la gestión de sistemas complejos.